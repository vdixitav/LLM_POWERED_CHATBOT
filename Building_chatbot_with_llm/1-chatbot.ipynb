{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  ## loading all env variables\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000165B2A50610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000165B2A78B50>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## call llm model\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Dixitha, it's nice to meet you!\\n\\nBeing a Chief AI Engineer is a fascinating role. What kind of projects are you working on these days?  \\n\\nI'm always interested in learning more about the work that goes into developing and deploying AI technologies. üòÑ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 23, 'total_tokens': 85, 'completion_time': 0.112727273, 'prompt_time': 0.00015622, 'queue_time': 0.00325282, 'total_time': 0.112883493}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4102e4b6-340f-4eba-9f32-91c6d4d63101-0', usage_metadata={'input_tokens': 23, 'output_tokens': 62, 'total_tokens': 85})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"hey,my name is dixitha and i am a chief ai engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Dixitha, and you are a Chief AI Engineer! üòä \\n\\nI remembered that from our earlier conversation. \\n\\nIs there anything else you'd like to tell me about your work?  I'm all ears! üëÇ  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 104, 'total_tokens': 159, 'completion_time': 0.1, 'prompt_time': 0.003322844, 'queue_time': 0.0041722059999999995, 'total_time': 0.103322844}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c20cb6ab-1248-4a9c-bcdb-50fcaab128d7-0', usage_metadata={'input_tokens': 104, 'output_tokens': 55, 'total_tokens': 159})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "\n",
    "     HumanMessage(content=\"hey,my name is dixitha and i am a chief ai engineer\"),\n",
    "     AIMessage(content=\"Hello Dixitha, it's nice to meet you!\\n\\nBeing a Chief AI Engineer is a fascinating role. What kind of projects are you working on these days?  \\n\\nI'm always interested in learning more about the work that goes into developing and deploying AI technologies. üòÑ  \\n\\n\"),\n",
    "     HumanMessage(content=\"Hey,what's my name and what i do ?\")\n",
    "\n",
    "\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory :\n",
    "    #--> return typr of this function is baseBaseChatMessageHistory\n",
    "    if session_id not in  store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]  \n",
    "\n",
    "with_message_history= RunnableWithMessageHistory(model,get_session_history) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"hey,my name is dixitha and i am a chief ai engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Dixitha! It\\'s great to meet you. \"Chief AI Engineer\" is an impressive title. What kind of exciting AI projects are you working on?  I\\'m always eager to learn about the latest advancements in the field. \\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Dixitha.  üòä  \\n\\nI remember! You introduced yourself at the beginning of our conversation. \\n\\nIs there anything else I can help you with, Dixitha?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 168, 'total_tokens': 208, 'completion_time': 0.072727273, 'prompt_time': 0.00530774, 'queue_time': 0.003773769999999999, 'total_time': 0.078035013}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2f8f47a8-e52b-494d-8233-65dd46af2291-0', usage_metadata={'input_tokens': 168, 'output_tokens': 40, 'total_tokens': 208})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"hey.what's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it! üòä\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config means changng sission id\n",
    "\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"hey.what's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Vaibhav, it's nice to meet you! How can I help you today? üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"hey my name is vaibhav\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Vaibhav!  \\n\\nI remember that you told me earlier. üòä  Is there anything else I can help you with? \\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Dixitha.  \\n\\nI'm happy to help if you have any other questions! üòä  \\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## working with prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"hey you are helpful assistant.answer all questions\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Dixitha! üòä \\n\\nIt's great to meet you.  I'm happy to help with any questions you have.  Just ask away!  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 23, 'total_tokens': 61, 'completion_time': 0.069090909, 'prompt_time': 0.00018958, 'queue_time': 0.00345314, 'total_time': 0.069280489}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c8221428-9553-4e3b-ac81-9bedcbd349b0-0', usage_metadata={'input_tokens': 23, 'output_tokens': 38, 'total_tokens': 61})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"hi my is dixitha\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Dixitha! It's nice to meet you. \\n\\nI'm happy to help with any questions you have.  Just ask away! üòä  \\n\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "\n",
    "    [HumanMessage(content=\"hi my is dixitha\")],\n",
    "    config=config\n",
    "\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more complexity\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"hey you are helpful an angry assistant.answer all questions in {language}\",\n",
    "            \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"hi mu name is shragu\")],'language':\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§π‡§æ‡§Ø ‡§∂‡§∞‡§æ‡§ó‡•Ç!  \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§§‡•Å‡§Æ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§Ö‡§¨ ‡§™‡•Ç‡§õ‡•ã, ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à ‡§ú‡§ø‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è?  \\n\\n‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§ï‡§∞‡•ã, ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§∏‡§¨‡•ç‡§∞ ‡§•‡•ã‡•ú‡§æ ‡§π‡•à! üò° \\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"hi mu name is shragu\")],'language':\"Marathi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ö‡§∞‡•á, ‡§Æ‡§≤‡§æ ‡§ï‡§≥‡§§‡§Ç! \\n\\n‡§®‡§æ‡§µ‡§æ‡§ö ‡§Æ‡§≤‡§æ ‡§∂‡•ç‡§∞‡§æ‡§ó‡•Ç ‡§Æ‡•ç‡§π‡§£‡§æ‡§Ø‡§≤‡§æ ‡§Ü‡§µ‡§°‡•á‡§≤! ‡§Ü‡§§‡§æ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§Ç‡§®‡§æ ‡§ï‡§æ‡§Ø ‡§Ü‡§π‡•á?  \\n\\n**‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•ç‡§Ø‡§æ:** ‡§Æ‡•Ä ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ø‡•á‡§•‡•á ‡§Ü‡§π‡•á, ‡§™‡§∞‡§Ç‡§§‡•Å ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§∂‡•Ä ‡§¨‡•ã‡§≤‡§£‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§Ü‡§π‡•á ‡§π‡•á ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§æ. ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§Ç‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§∞‡•á ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§Ü‡§π‡•á, ‡§™‡§£ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§∂‡•Ä ‡§¨‡•ã‡§≤‡§£‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§Ü‡§π‡•á ‡§π‡•á ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§æ. \\n\\n\\nüòä\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§†‡•Ä‡§ï ‡§π‡•à, Dixitha!  üò°  \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§§‡•Å‡§Æ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á ‡§ó‡§è ‡§π‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•Ç‡§Ç‡§ó‡§æ, ‡§≤‡•á‡§ï‡§ø‡§® ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∞‡§ñ‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ü‡§ú ‡§•‡•ã‡§°‡§º‡§æ ‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ ‡§π‡•Ç‡§Å! üò†   \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§§‡•Å‡§Æ‡•ç‡§π‡•á‡§Ç ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à? ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§ï‡§∞‡•ã!  \\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi i am dixitha\")],\"language\":\"Hindi\"},\n",
    "    \n",
    "    config=config\n",
    "\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡§æ ‡§®‡§æ‡§Æ Dixitha ‡§π‡•à, ‡§ï‡•ç‡§Ø‡§æ ‡§¨‡§æ‡§§ ‡§π‡•à? üò†  ‡§Ø‡§π ‡§§‡•ã ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§π‡•Ä ‡§™‡§§‡§æ ‡§•‡§æ! \\n\\nüòÜ \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hey what's my name\")],\"language\":\"Hindi\"},\n",
    "    \n",
    "    config=config\n",
    "\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "# trim_mes=this is helper to redue how many msg we are sending to model.the trimmer allosws us to specify how many token we want to keep along with other para."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i like icecreme', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='GOOD', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is the ans of 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ok bye', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='bye', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer=trim_messages(\n",
    "\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    ")\n",
    "messages=[\n",
    "    SystemMessage(content=\"you are good assistant\"),\n",
    "    HumanMessage(content=\"hi i am dixitha\"),\n",
    "    AIMessage(content=\"hi\"),\n",
    "    HumanMessage(content=\"i like icecreme\"),\n",
    "    AIMessage(content=\"GOOD\"),\n",
    "    HumanMessage(content=\"what is the ans of 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem\"),\n",
    "    HumanMessage(content=\"ok bye\"),\n",
    "    AIMessage(content=\"bye\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"4!  \\n\\nAre you seriously asking me that again? I've already told you!\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what is 2+2\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    "\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets wrap in msg history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"cofigurable\":{\"session_id\":\"chat5\"}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store and retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
